{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Notas examen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "Dividir los datos en train y test. Esto para entrenar tu modelo con unos datos y probarlo en datos que no ha visto y ver que tan bueno fue. Es con el objetivo de evitar overfitting, o sea que el modelo pueda generalizar y no memorizar los datos.\n",
    "\n",
    "---\n",
    "\n",
    "## Teorema Frisch-Waugh-Lovell\n",
    "\n",
    "$$\n",
    "\\hat y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3\n",
    "$$\n",
    "Esta es la regresión lineal original con todas las variables, y se busca encontrar el efecto causal de la variable $x_1$.\n",
    "\n",
    "$$\n",
    "\\hat y = \\theta_0 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "$$\n",
    "Para ello haces la regresión lineal para $y$ sin utilizar $x_1$.\n",
    "\n",
    "$$\n",
    "y - \\hat y = \\text{residuales y}\n",
    "$$\n",
    "Y obtienes los residuales entre tu regresión sin $x_1$ y los valores reales de $y$. Estos residuales de $y$ es lo que no pueden explicar $x_2$ y $x_3$ de $y$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat {x_1} = \\gamma_0 + \\gamma_2 x_2 + \\gamma_3 x_3\n",
    "$$\n",
    "Posteriormente realizas una regresión lineal para $x_1$ con las variables $x_2$ y $x_3$.\n",
    "\n",
    "$$\n",
    "x_1 - \\hat {x_1} = \\text{residuales x}\n",
    "$$\n",
    "Y calculas los residuales entre tu predicción de $\\hat {x_1}$ y $x_1$ real. Estos residuales de $x_1$ es lo que no pueden explicar  $x_2$ y $x_3$ de $x_1$\n",
    "\n",
    "$$\n",
    "y - \\hat y = \\beta_1(x_1 - \\hat {x_1})\n",
    "$$\n",
    "Por útlimo realizas un regresión de los residuales de $y$ contra los residuales de $x_1$, y la $B_1$ resultante es la misma que la $B_1$ de la regresión original, lo cual sería el efecto causal de $x_1$ sobre $y$.\n",
    "\n",
    "---\n",
    "\n",
    "## R2\n",
    "\n",
    "Es el porcentaje de la variación de los datos explicada por nuestro modelo. Suele estar entre 0 y 1, mientras es más cercana a 1 significa que el modelo explica bien la variación de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "## Descenso en gradiente\n",
    "\n",
    "Proceso iterativo el cual busca minimizar tu error (función de pérdida) actualizando los valores de las $\\beta$'s de tu regresión a través de derivadas parciales.\n",
    "\n",
    "Tienes la función de pérdida: $L = \\frac{1}{2} \\sum (\\hat y - y)^2$\n",
    "\n",
    "Para este ejemplo $\\hat y = \\beta_0 + \\beta_1 x_1$\n",
    "\n",
    "Tu buscas:\n",
    "$$\n",
    "min \\quad \\frac{1}{2} \\sum (\\hat y - y)^2\n",
    "$$\n",
    "\n",
    "Para eso realizas de forma iterativa lo siguiente ($\\alpha$ es tasa de aprendizaje): $\\beta_1 = \\beta - \\alpha \\frac{\\partial L}{\\partial \\beta}$\n",
    "\n",
    "Cada $\\beta$ se actualiza restándole la derivada parcial de $L$ multiplicada por la tasa de aprendizaje $\\alpha$, la cual ayuda a que el cambio en la $\\beta$ no sea tan grande. Esta nueva $\\beta$ se utiliza para recalcular la función de pérdida y se vuelve a actualizar en cada iteración, restando nuevamente la derivada parcial multiplicada por la tasa de aprendizaje. Este proceso se repite hasta que el modelo converge.\n",
    "\n",
    "El método funciona porque al hacer la resta, el signo negativo invierte la dirección de la pendiente obtenida en la derivada después de cada iteración, ayudando a la convergencia.\n",
    "\n",
    "---\n",
    "\n",
    "## Análisis bivariado\n",
    "\n",
    "El análisis bivariado es una técnica estadística que estudia la relación entre dos variables. Su objetivo es identificar patrones, asociaciones o correlaciones entre ellas. Ves en una gráfica la forma de la relación lo cual brinda información para hacer mejores variables para el modelo, puede ayudar a hacer transformaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## KNN\n",
    "\n",
    "KNN (K-Nearest Neighbors) es un algoritmo de aprendizaje supervisado usado para clasificación y regresión. Su principio es simple: predice un valor o categoría basado en los K vecinos más cercanos en el espacio de características.\n",
    "\n",
    "\n",
    "1- Se elige un número  K de vecinos (hiperparámetro).\n",
    "\n",
    "2- Para una nueva observación, se calculan las distancias con todos los datos de entrenamiento.\n",
    "\n",
    "3- Se seleccionan los  K vecinos más cercanos. \n",
    "\n",
    "4- Se predice el promedio de los valores de los K vecinos.\n",
    "\n",
    "---\n",
    "\n",
    "## A/B test\n",
    "\n",
    "El AB testing consiste en dividir un grupo de personas en dos grupos, un grupo grande en el que se mantiene todo igual y un grupo pequeño en el que se hace una modificación, esto con el fin de ver si este cambio tiene un impacto positivo o negativo, y así ver si conviene implementarlo. Para comprobar si este efecto es estadísticamente significativo se realiza una prueba de hipótesis, en el que la hipótesis nula es que no hay diferencia entre los grupos y la hipótesis alterna es que si hay diferencia entre los grupos. Para esto se calcula el valor de z con el que obtienes el p-value y este se compara con el nivel de significancia establecido para saber si rechazar o no la hipótesis nula."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
