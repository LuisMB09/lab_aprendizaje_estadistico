{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sección 1: Conceptos Teóricos (40 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts) ¿Cuál es la diferencia entre una regresión lineal simple y una regresión lineal múltiple? Da un ejemplo de cada una.**\n",
    "\n",
    "La regresión lineal simple utiliza una variable independiente para predecir la dependiente. Un ejemplo sería utilizar la estatura para predecir el peso.\n",
    "\n",
    "Modelo: $$ \\hat y = \\beta_0 + \\beta_1 x_1 $$\n",
    "\n",
    "La regresión lineal múltiple utiliza varias variables independientes para predecir la dependiente. Un ejemplo sería usar la temperatura, sensación térmica, humedad, día de la semana y estación del año para pronosticar la cantidad de bicis que se rentan en una ciudad.\n",
    "\n",
    "Modelo: $$ \\hat y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ ... \\ + \\beta_n x_n $$\n",
    "\n",
    "**(5 pts) Explica el problema de overfitting y cómo podrías mitigarlo**\n",
    "\n",
    "Ocurre cuando el modelo obtenido memoriza los datos en lugar de aprender, por lo que no puede generalizar pues es muy malo en datos no vistos por el modelo. Para mitigarlo se puede hacer cross validation, donde una parte de los datos son para entrenar al modelo y otra para probarlo (datos no vistos) e intentas que mejore el modelo en el test. Además utilizar regularización Ridge o Lasso en una regresión lineal puede ayudar a no hacer overfitting.\n",
    "\n",
    "**(5 pts) En regresión polinomial, ¿por qué es necesario realizar un análisis de validación cruzada antes de elegir el grado del polinomio?**\n",
    "\n",
    "La razón prinicpal es para evitar el problema de overfitting, pues no te interesa que el modelo memorice, sino que sea capaza de predecir con base en nuevas entradas. Esto se debe a que un modelo de grado muy alto puede ajustarse muy bien a los datos, sin embargo, ser incapaz de generalizar y hacer buenas predicciones\n",
    "\n",
    "**(5 pts) ¿Qué es una prueba de hipótesis en el contexto de regresión lineal? Explica cómo se interpreta el p-value de un coeficiente.**\n",
    "\n",
    "La prueba de hipótesis nos dice si las $\\beta$'s son significativas o no, para ello calcula el estadístico de t de estas el cual nos dice a cuantas desviaciones estándar esta $\\beta$ de 0, y se obtiene el p-value asociado al valor de t obtenido, y a partir de esto decide si la variable es significativa o no.\n",
    "\n",
    "Si la variable tiene un p-value mayor a 0.05 (o valor de umbral establecido), significa que la variable no es significativa para la regresión, lo cual indica que muy posiblemente la variable no aporte información al modelo. Si es menor a 0.05 el p-value de la variable significa que si aporta al modelo y es una variable útil.\n",
    "\n",
    "**(5 pts) ¿Por qué convertir variables categóricas en dummies puede mejorar el desempeño de un modelo? ¿En qué casos podríamos usar una codificación diferente?**\n",
    "\n",
    "Puede ayudar a darle más información al modelo que sea útil para predecir. Por ejemplo, si tienes una columna que sea el día de la semana, lo necesitas de forma numércia para que sea utilizable para el modelo, entonces tendrías 7 columnas, donde es 1 si ese día de la semana y 0 si no, esto ayuda al modelo a captar si afecta que sea algún día en particular lo cual puede ser bueno.\n",
    "\n",
    "Otra forma de hacerlo es transformar variables numéricas a categóricas a través de los bins, esto permite dividir tus variables numéricas en cuantiles hacinedola categórica. Tener estas categorías pueden ayudar a predecir al modelo basandose en si una observación pertence a algun cuantil. Por ejemplo si se tiene ingreso como variable, esta estrategia clasificaría a la gente con ingreso muy alto en un grupo, lo cual ayuda pues seguramente el ingreso muy alto tiene un comportamiento distinto en comparación con alguien de ingreso muy bajo.\n",
    "\n",
    "**(5 pts) Explica como se obtienen los coeficientes de una regresión lineal con decenso en gradiente (tanto para lineal como polinomio), me tiene que quedar claro que le entiendes**\n",
    "\n",
    "El descenso en gradiente es un proceso iterativo el cual busca minimizar tu error (función de pérdida) actualizando los valores de las $\\beta$'s de tu regresión a través de derivadas parciales.\n",
    "\n",
    "Tienes la función de pérdida: $L = \\frac{1}{2} \\sum (\\hat y - y)^2$\n",
    "\n",
    "Para este ejemplo $\\hat y = \\beta_0 + \\beta_1 x_1$\n",
    "\n",
    "Tu buscas:\n",
    "$$\n",
    "min \\quad \\frac{1}{2} \\sum (\\hat y - y)^2\n",
    "$$\n",
    "\n",
    "Para eso realizas de forma iterativa lo siguiente ($\\alpha$ es tasa de aprendizaje): $\\beta_1 = \\beta - \\alpha \\frac{\\partial L}{\\partial \\beta}$\n",
    "\n",
    "Cada $\\beta$ se actualiza restándole la derivada parcial de $L$ multiplicada por la tasa de aprendizaje $\\alpha$, la cual ayuda a que el cambio en la $\\beta$ no sea tan grande. Esta nueva $\\beta$ se utiliza para recalcular la función de pérdida y se vuelve a actualizar en cada iteración, restando nuevamente la derivada parcial multiplicada por la tasa de aprendizaje. Este proceso se repite hasta que el modelo converge. La derivada parcial se hace sobre todas las $\\beta$'s y todas se actualizan.\n",
    "\n",
    "El método funciona porque al hacer la resta, el signo negativo invierte la dirección de la pendiente obtenida en la derivada después de cada iteración, ayudando a la convergencia.\n",
    "\n",
    "**(5 pts) Explica que es el teorema de Frisch-Waugh-Lovell**\n",
    "\n",
    "Para una regresión lineal multiple $ \\hat y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 $, la $\\beta_1$ puede obtenerse a través de un método, logrando explicar el efecto causal de una variable.\n",
    "\n",
    "$$\n",
    "\\hat y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3\n",
    "$$\n",
    "Esta es la regresión lineal original con todas las variables, y se busca encontrar el efecto causal de la variable $x_1$.\n",
    "\n",
    "$$\n",
    "\\hat y = \\theta_0 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "$$\n",
    "Para ello haces la regresión lineal para $y$ sin utilizar $x_1$.\n",
    "\n",
    "$$\n",
    "y - \\hat y = \\text{residuales y}\n",
    "$$\n",
    "Y obtienes los residuales entre tu regresión sin $x_1$ y los valores reales de $y$. Estos residuales de $y$ es lo que no pueden explicar $x_2$ y $x_3$ de $y$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat {x_1} = \\gamma_0 + \\gamma_2 x_2 + \\gamma_3 x_3\n",
    "$$\n",
    "Posteriormente realizas una regresión lineal para $x_1$ con las variables $x_2$ y $x_3$.\n",
    "\n",
    "$$\n",
    "x_1 - \\hat {x_1} = \\text{residuales x}\n",
    "$$\n",
    "Y calculas los residuales entre tu predicción de $\\hat {x_1}$ y $x_1$ real. Estos residuales de $x_1$ es lo que no pueden explicar  $x_2$ y $x_3$ de $x_1$\n",
    "\n",
    "$$\n",
    "y - \\hat y = \\beta_1(x_1 - \\hat {x_1})\n",
    "$$\n",
    "Por útlimo realizas un regresión de los residuales de $y$ contra los residuales de $x_1$, y la $B_1$ resultante es la misma que la $B_1$ de la regresión original, lo cual sería el efecto causal de $x_1$ sobre $y$.\n",
    "\n",
    "\n",
    "**(5 pts) Explica que es K-nearest neighboors**\n",
    "\n",
    "Es un modelo que puede utilizarse para predecir o clasificar, basadóse en el número de vecinos más cercanos según las características del punto.\n",
    "\n",
    "El modelo funciona eligiendo un número de vecinos (K), para un nuevo dato calcula las distancias con todos los datos que son parte de tu entrenamiento, y selecciona a los K vecinos más cercanos. Si elegista 3 vecinos, entonces selecciona a los 3 puntos más cercanos. Y la predicción es el promedio de los valores de los K vecinos más cercanos.\n",
    "\n",
    "Si el vecino 1 = 8, vecino 2 = 15 y vecino 3 = 4, entonces la predicción sería el promedio que es 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sección 2 (20 puntos)\n",
    "\n",
    "(10 pts) Dado el siguiente dataset de casas:\n",
    "\n",
    "```\n",
    "data = pd.DataFrame({\n",
    "    \"Tamaño_m2\": [50, 80, 120, 200, 150, 90, 175, 60, 220, 130],\n",
    "    \"Habitaciones\": [1, 2, 3, 4, 3, 2, 3, 1, 5, 3],\n",
    "    \"Precio_1000s\": [110, 170, 250, 400, 270, 200, 330, 190, 600, 380]  })\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "a) Ajusta una regresión lineal para predecir el precio en función del tamaño y número de habitaciones, dime el R2 y coeficientes.\n",
    "\n",
    "\n",
    "b) Imagina que el coeficiente de Tamaño es 2.5 y el coeficiente de Habitaciones es 20, ¿cómo interpretarías estos valores?  \n",
    "\n",
    "(20 pts) Imagina que entrenas un modelo de regresión polinomial de grado 5 y obtienes un 𝑅2 de 0.98 en el conjunto de entrenamiento y 0.65 en el conjunto de prueba.\n",
    "\n",
    "- a) ¿Qué problema podrías estar enfrentando?\n",
    "- b) ¿Cómo lo solucionarías sin reducir demasiado la capacidad del modelo?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tamaño_m2</th>\n",
       "      <th>Habitaciones</th>\n",
       "      <th>Precio_1000s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tamaño_m2  Habitaciones  Precio_1000s\n",
       "0         50             1           110\n",
       "1         80             2           170\n",
       "2        120             3           250\n",
       "3        200             4           400\n",
       "4        150             3           270"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"Tamaño_m2\": [50, 80, 120, 200, 150, 90, 175, 60, 220, 130],\n",
    "    \"Habitaciones\": [1, 2, 3, 4, 3, 2, 3, 1, 5, 3],\n",
    "    \"Precio_1000s\": [110, 170, 250, 400, 270, 200, 330, 190, 600, 380]})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Precio_1000s   R-squared:                       0.866\n",
      "Model:                            OLS   Adj. R-squared:                  0.828\n",
      "Method:                 Least Squares   F-statistic:                     22.66\n",
      "Date:                Tue, 18 Feb 2025   Prob (F-statistic):           0.000876\n",
      "Time:                        20:49:36   Log-Likelihood:                -53.255\n",
      "No. Observations:                  10   AIC:                             112.5\n",
      "Df Residuals:                       7   BIC:                             113.4\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -0.0869     47.302     -0.002      0.999    -111.939     111.765\n",
      "Tamaño_m2        0.4469      1.191      0.375      0.719      -2.370       3.264\n",
      "Habitaciones    86.3339     55.729      1.549      0.165     -45.443     218.111\n",
      "==============================================================================\n",
      "Omnibus:                        1.959   Durbin-Watson:                   0.504\n",
      "Prob(Omnibus):                  0.375   Jarque-Bera (JB):                1.018\n",
      "Skew:                           0.430   Prob(JB):                        0.601\n",
      "Kurtosis:                       1.695   Cond. No.                         418.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_stats_py.py:1971: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  k, _ = kurtosistest(a, axis)\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('Precio_1000s ~ Tamaño_m2 + Habitaciones', data=data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8661894650001757"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(data['Precio_1000s'], model.predict(data[['Tamaño_m2', 'Habitaciones']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inciso a)\n",
    "El r^2 del modelo es de 0.866, lo que significa que explica un 86.6% de la variacón de los datos.\n",
    "\n",
    "Coeficientes:\n",
    "\n",
    "- Intercepto: -0.0869\n",
    "- Tamaño_m2 = 0.4469\n",
    "- Habitaciones = 86.339"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inciso b\n",
    "\n",
    "b) Imagina que el coeficiente de Tamaño es 2.5 y el coeficiente de Habitaciones es 20, ¿cómo interpretarías estos valores?  \n",
    "\n",
    "Por cada metro cuadrado extra, el precio de la casa aumenta 2,500, y por cada habitación extra el valor de la casa aumenta 20,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 pts) Imagina que entrenas un modelo de regresión polinomial de grado 5 y obtienes un 𝑅2 de 0.98 en el conjunto de entrenamiento y 0.65 en el conjunto de prueba.\n",
    "\n",
    "- a) ¿Qué problema podrías estar enfrentando?\n",
    "- b) ¿Cómo lo solucionarías sin reducir demasiado la capacidad del modelo?\n",
    "\n",
    "En este caso sería un problema de overfitting pues funciona muy bien en los datos de entrenamiento pero en los de prueba realiza malas predicciones.\n",
    "\n",
    "Para solucionar el problema se pueden realizar varias cosas, una sería usar regularización Ridge o Lasso, otra hacer un análisis bivariado de las variables contra el target para ver su relación y saber si vale la pena hacer transformaciones, o analizar la correlación entre variables y ver si hay algunas que no aporten al modelo y quitarlas.\n",
    "\n",
    "Ya por último se puede reducir el grado del polinomio pero esto si podría afcetar su capacidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sección 3: Implementación de Código (40 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1- En el dataset Advertising.csv estan las ventas de una empresa y hay 3 canales de distribuición:\n",
    "    \n",
    "- radio\n",
    "- Televisión\n",
    "- Periodico\n",
    "\n",
    "\n",
    "La empresa quiere simplificar su operción y eliminar aquellos canales que no traen ventas.\n",
    "\n",
    "Dime que canal o canales no sirven con una prueba de hipotesis y una regresión\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  radio  newspaper  sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Advertising.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Tue, 18 Feb 2025   Prob (F-statistic):           1.58e-96\n",
      "Time:                        21:05:31   Log-Likelihood:                -386.18\n",
      "No. Observations:                 200   AIC:                             780.4\n",
      "Df Residuals:                     196   BIC:                             793.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
      "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         454.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('sales ~ TV + radio + newspaper', data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta regresión lineal vemos como cada una de las variables afecta a sales a través de los coeficientes. Tanto TV como radio son postivas, por lo que a mayor cantidad en esas variables las ventas aumentan. Podemos notar que newspaper tiene un coeficiente negativo, lo cual significa que a mayor en newspaper nuestras ventas se reducen, lo que significa que no deberíamos usar newspaper pues afecta a nuestras ventas.\n",
    "\n",
    "Además analizando los p-values de nuestras variables vemos que el de newspaper es 0.860, lo que implica que no es significativo, por lo que no aporta información útil para las predicciones del modelo, por lo que se puede quitar.\n",
    "\n",
    "En conclusión la empresa debería quitar el canal de vetas de newspapaer pues afceta de forma negativa las ventas y su p-value es muy alto por lo que no es significativa para nuestro modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
