{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='navy'> ¿Qué es?  <font color='black'>\n",
    "\n",
    "Es un modelo utilizado para predecir la probabilidad de ocurrencia de un evento binario. Se utiliza principalmente en problemas de clasificación donde existen dos clases, con base en esta probabilidad calculada asigna una clase a la observación. Habitualmente si $p > 0.5$ se clasifica como 1, si $p < 0.5$ se clasifica como 0.\n",
    "\n",
    "Para calcular las probabilidades de predicción se realiza lo siguiente:\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='navy'> ¿Cómo se calcula?  <font color='black'>\n",
    "\n",
    "$$\n",
    "z (\\text{log odds}) = \\beta^T X\n",
    "$$\n",
    "\n",
    "p se calcula:\n",
    "\n",
    "$$\n",
    "p = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='navy'> Verosimilitud  <font color='black'>\n",
    "\n",
    "Dado un conjunto de datos $(X_i, y_i)$ con \\( i = 1, $\\dots$, m \\), la **función de verosimilitud** es:\n",
    "\n",
    "$$\n",
    "L(\\theta, \\sigma^2) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Tomamos el **logaritmo de la verosimilitud**:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta, \\sigma^2) = \\sum_{i=1}^{m} \\left( -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "#### **Relación con OLS**  \n",
    "\n",
    "Para **maximizar la verosimilitud respecto a $\\theta$ **, ignoramos términos constantes:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\sum_{i=1}^{m} -\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "Esto equivale a **minimizar el error cuadrático**:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{i=1}^{m} (y_i - \\theta^T X_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "**Conclusión:** Minimizar el error cuadrático con **OLS** es lo mismo que **maximizar la verosimilitud** bajo una **distribución normal de los errores**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='navy'> Odds y Log Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='navy'> Odds  <font color='black'>\n",
    "\n",
    "**Odds:** Mi equipo gana 1 a 4\n",
    "\n",
    "Eso significa que odds = $\\frac{1}{4}$\n",
    "\n",
    "**Probabilidad de ganar:** \n",
    "\n",
    "$$\n",
    "\\frac{1}{1+4} = 0.2\n",
    "$$\n",
    "\n",
    "**Probabilidad de perder:** \n",
    "\n",
    "$$\n",
    "1 - \\frac{1}{1+4} = 0.8\n",
    "$$\n",
    "\n",
    "#### Otro ejemplo:\n",
    "\n",
    "**Odds:** Mi equipo gana 5 a 3\n",
    "\n",
    "Eso significa que odds = $\\frac{5}{3}$\n",
    "\n",
    "**Probabilidad de ganar:** \n",
    "\n",
    "$$\n",
    "\\frac{5}{5+3} = 0.625\n",
    "$$\n",
    "\n",
    "**Probabilidad de perder:** \n",
    "\n",
    "$$\n",
    "1 - \\frac{5}{5+3} = 0.375\n",
    "$$\n",
    "\n",
    "**Definición.** La probabilidad de ganar entre la probabilidad de perder.\n",
    "\n",
    "$$\n",
    "odds = \\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $p$ es la probabilidad de ganar.\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='navy'> Log Odds  <font color='black'>\n",
    "\n",
    "$$\n",
    "ln (odds) = ln (\\frac{p}{1-p})\n",
    "$$\n",
    "\n",
    "Los coeficientes de la regresión logística se multiplican por X al igual que en la regresión lineal.\n",
    "\n",
    "z (log odds) se calcula:\n",
    "\n",
    "$$\n",
    "z = \\beta^T X\n",
    "$$\n",
    "\n",
    "p se calcula:\n",
    "\n",
    "$$\n",
    "p = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Si $p > 0.5$ se clasifica como 1, si $p < 0.5$ se clasifica como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='navy'> Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='navy'> ¿Qué es?  <font color='black'>\n",
    "\n",
    "Se utiliza similar a la regresión logística, pero para problemas de clasificación de más de dos clases.\n",
    "\n",
    "La función Softmax convierte los logits (salidas de la función lineal) en probabilidades:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### <font color='navy'> Ejemplo Numérico  <font color='black'>\n",
    "Si tenemos 3 clases y logits calculados como:\n",
    "$$\n",
    "z_1 = 2.0, \\quad z_2 = 1.0, \\quad z_3 = -1.0\n",
    "$$\n",
    "Aplicamos Softmax:\n",
    "$$\n",
    "P(y=1) = \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72\n",
    "$$\n",
    "$$\n",
    "P(y=2) = \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26\n",
    "$$\n",
    "$$\n",
    "P(y=3) = \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04\n",
    "$$\n",
    "Esto indica que la clase 1 es la más probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>thetas0</th>\n",
       "      <th>thetas1</th>\n",
       "      <th>thetas2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>-0.235408</td>\n",
       "      <td>0.400842</td>\n",
       "      <td>-0.165434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malic_acid</td>\n",
       "      <td>-0.014920</td>\n",
       "      <td>-0.585382</td>\n",
       "      <td>0.600302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ash</td>\n",
       "      <td>0.118567</td>\n",
       "      <td>-0.136948</td>\n",
       "      <td>0.018381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alcalinity_of_ash</td>\n",
       "      <td>-0.228178</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.226297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>magnesium</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.053547</td>\n",
       "      <td>-0.069103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_phenols</td>\n",
       "      <td>0.229336</td>\n",
       "      <td>0.154185</td>\n",
       "      <td>-0.383521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flavanoids</td>\n",
       "      <td>0.403906</td>\n",
       "      <td>0.352244</td>\n",
       "      <td>-0.756149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nonflavanoid_phenols</td>\n",
       "      <td>-0.018296</td>\n",
       "      <td>-0.015802</td>\n",
       "      <td>0.034098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proanthocyanins</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.309328</td>\n",
       "      <td>-0.313841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>color_intensity</td>\n",
       "      <td>-0.128707</td>\n",
       "      <td>-1.230895</td>\n",
       "      <td>1.359602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hue</td>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.192869</td>\n",
       "      <td>-0.207354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>od280/od315_of_diluted_wines</td>\n",
       "      <td>0.206818</td>\n",
       "      <td>0.433286</td>\n",
       "      <td>-0.640104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>proline</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>-0.007919</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       variables   thetas0   thetas1   thetas2\n",
       "0                        alcohol -0.235408  0.400842 -0.165434\n",
       "1                     malic_acid -0.014920 -0.585382  0.600302\n",
       "2                            ash  0.118567 -0.136948  0.018381\n",
       "3              alcalinity_of_ash -0.228178  0.001881  0.226297\n",
       "4                      magnesium  0.015556  0.053547 -0.069103\n",
       "5                  total_phenols  0.229336  0.154185 -0.383521\n",
       "6                     flavanoids  0.403906  0.352244 -0.756149\n",
       "7           nonflavanoid_phenols -0.018296 -0.015802  0.034098\n",
       "8                proanthocyanins  0.004513  0.309328 -0.313841\n",
       "9                color_intensity -0.128707 -1.230895  1.359602\n",
       "10                           hue  0.014485  0.192869 -0.207354\n",
       "11  od280/od315_of_diluted_wines  0.206818  0.433286 -0.640104\n",
       "12                       proline  0.006856 -0.007919  0.001063"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar el dataset Wine\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Crear un DataFrame con nombres de columnas\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df[\"target\"] = y  # Agregar la columna de la clase\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "target = 'target'\n",
    "\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "# Normalizar las características\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Logística Multiclase (Softmax)\n",
    "model = linear_model.LogisticRegression(multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "coeficientes = pd.DataFrame({\n",
    "    'variables': X_train.columns,\n",
    "    'thetas0': model.coef_[0],\n",
    "    'thetas1': model.coef_[1],\n",
    "    'thetas2': model.coef_[2]\n",
    "})\n",
    "coeficientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las $\\theta$'s generan los valores de z ($\\theta^T X$) que se introducen al softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='navy'> Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
