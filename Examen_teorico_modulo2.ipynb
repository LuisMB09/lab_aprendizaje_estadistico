{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58182883-edf4-410e-9fb5-3cc408d49dfb",
   "metadata": {},
   "source": [
    "# Examen modulo 2\n",
    "\n",
    "\n",
    "## **Sección 1: Regresión Logística** (30 puntos)  \n",
    "\n",
    "1. **(10 pts) Explica la diferencia entre la regresión logística **lineal** y la **polinomial**. ¿En qué casos es recomendable usar la versión polinomial?**  \n",
    "\n",
    "La regresión logística lineal utiliza los features $X$ como están para hacer las predicciones de las probabilidades, mientras que la polinomial usa los features $X$, $X^2$, $X^3$ etc; hasta el grado del polinomio especificado. Esto ocurre al igual que con la regresión lineal.\n",
    "\n",
    "De forma gráfica la logística lineal separa los datos con una línea recta, mientras que la polinomial los separa con una curva del polinomio utilizado.\n",
    "\n",
    "La versión polinomial puede ser de utilidad cuando los datos tengan relaciones complejas respecto a la clase a la que pertencen y esta pueda ser una relación no lineal, donde gráficamente sea conveniente seprar los datos con una curva.\n",
    "\n",
    "2. **(10 pts) Explica como mediante decenso en gradiente y maxima verosimilitud creamos una regresión lógisitca**  \n",
    "\n",
    "Primero veamos como se calcula la probabilidad dentro de la regresión logística:\n",
    "\n",
    "$$\n",
    "p(y = 1 | X) = \\sigma(\\theta^T X) = \\frac{1}{1 + e^{-\\theta^T X}}\n",
    "$$\n",
    "\n",
    "La variable $y$ sigue un distribución de Bernoulli, por lo que la verosimilitud se calcula de la siguiente manera:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "donde se sustituye $p$ (probabilidad de éxito) por $\\sigma(\\theta^T X_i)$\n",
    "\n",
    "Tomamos el logaritmo de la función para maximizar la verosimilitud:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "El objetivo es maximizar esta función, por lo que aplicamos ascenso en gradiente. Este proceso es similar al descenso en gradiente, primero se calculan los valores predichos y la función objetivo con valores iniciales de $\\theta$. Posteriormente, se obtiene la derivada parcial de $J(\\theta)$ respecto a cada $\\theta$ y se actualizan los coeficientes de manera iterativa.\n",
    "\n",
    "La diferencia principal respecto al descenso en gradiente es que, en este caso, se suma la derivada parcial multiplicada por la tasa de aprendizaje $\\alpha$, en lugar de restarla:\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha \\frac{\\partial J}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "Este proceso se repite, donde en cada iteración se actualizan los coeficientes y se calcula el valor de la función hasta encontrar los valores de $\\theta$ que maximizan la log-verosimilitud.\n",
    "\n",
    "3. **(10 pts) Explica el concepto de **odds** y **log-odds** en regresión logística. ¿Por qué la regresión logística predice el **log-odds** en lugar de la probabilidad directamente? Justifica esto**   \n",
    "\n",
    "Las odds son la razón entre la probabilidad de ocurrencia entre la probabilidad de no ocurrencia:\n",
    "\n",
    "$$\n",
    "odds = \\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "Un ejemplo son las casa de apuesta donde dice que las odds son de 1 a 4. Donde $p$ sería:\n",
    "\n",
    "$$\n",
    "\\frac{1}{1+4} = 0.2\n",
    "$$\n",
    "\n",
    "Las log-odds son simplemente el el logaritmo de las odds:\n",
    "\n",
    "$$\n",
    "ln (odds) = ln (\\frac{p}{1-p})\n",
    "$$\n",
    "\n",
    "Las odds dentro de un modelo de regresión logística pueden llegar a ser muy volátiles y un comportamiento bastante disperso, haciendo difícil entenderlas y como influyen en el modelo. Para evitar este probelma se una las log-odds, esto hace que se estabilicen y las mantiene dentro de un rango y con un mejor compartamiento, en un histograma se verían más estables. Esto ayuda a entender mejor el modelo, sus predicciones y la influencia de las variables sobre el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## **Sección 2: Área Bajo la Curva (AUC)** (20 puntos)  \n",
    "\n",
    "7. **(5 pts) Define la **curva ROC** y el AUC. ¿Qué tiene de especial?**\n",
    "\n",
    "La curva ROC es una gráfica que nos dice el desempeño del modelo para todo umbral de decisión, es decir, para cuando $1 \\ \\text{si} \\ p > 0.1$, $1 \\ \\text{si} \\ p > 0.2$, etc. El AUC es el área debajo de esta curva, esta métrica nos dice que tan bueno es el modelo para distinguir entre las clases.\n",
    "\n",
    "La curva ROC muestra la relación entre la sensitivity y la specificity para todos los umbrales posibles y el AUC nos dice que tan bueno es el modelo. Lo que tienen de especial es la capacidad para analizar el comportamiento y efectividad del modelo para todo umbral posible y no solo uno fijo, esto generaliza que tan bueno es el modelo en realidad.\n",
    "\n",
    "8. **(5 pts) Cuando hacemos una curva ROC, siempre ponemos una diagonal, explica que es esa diagonal**\n",
    "\n",
    "Divide el área en dos partes iguales con 0.5 de área cada una. Esta diagonal es prácticamente la curva ROC que se obtendría si hacemos predicciones al azar y representa un modelo sin capacidad de clasificación. Es un punto de referencia para otros modelos donde lo que desead es que este lo más por encima posible de esta línea.\n",
    "\n",
    "9. **(5 pts) Un modelo tiene un **AUC de 0.85**. Explica qué significa esto en términos de su capacidad de clasificación.** \n",
    "\n",
    "Significa que el modelo tiene una alta capacidad de distinguir entre las clases que se están prediciendo ya que tiene un área bajo la curva bastante alta. Por ejemplo (Titanic):\n",
    "\n",
    "Si se tienen las probabilidades predichas de los que sobreviven, y las probabilidades predichas de los que no sobreviven. El AUC es la probabilidad de que las predicciones de los que sobreviven sea mayor a las predicciones de los que no sobreviven.\n",
    "\n",
    "Si esta probabilidad es alta como este caso de 0.85, es 85% probable que la la probabilidad predicha para alguien de la clase 1 sea mayor a la de alguien de la clase 0, lo cual es algo bueno pues la predicción de la probabilidad de ser de la clase 1 quieres que sea lo más cercana a 1, mientras que las probabilidades predichas de la clase 0, sean lo más cercanas a 0.\n",
    "\n",
    "10. **(5 pts) Un modelo tiene accuracy de 99% pero AUC de 0.5%, ¿Cómo es que esto podría suceder?**\n",
    "\n",
    "El accuracy nos dice la proporción de predicciones correctas respecto a las predicciones totales, un 99% en esta métrica nos dice que estamos bien casi todo el tiempo, pero el AUC es muy bajo, por lo que no hay capacidad de distinguir entre las clases, esto se debería a unos datos muy desbalanceados.\n",
    "\n",
    "Por ejemplo, que casi todos sean 0 (99% de los datos) y muy pocos 1, esto haría que al entrenar el modelo prediga siempre 0 atinándole casi siempre al valor real y no pueda distinguir los pocos 1 que hay en los datos.\n",
    "\n",
    "---\n",
    "\n",
    "## **Sección 3: Análisis del Discriminante Lineal (LDA)** (10 puntos)  \n",
    "\n",
    "11. **(10 pts) ¿Qué es el análisis del discriminante lineal? ¿En que casos lo usarías? (gausiano)**\n",
    "\n",
    "Es un modelo de clasificación que trabaja bajo el supuesto de que los datos de cada clase siguen uns distribución normal multivariada de la siguiente forma:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Para realizar las predicciones utiliza la forma del teorema de Bayes para la cual se necesita la probabilidad de pertenencia de los datos a cada una de las clases (su proporción) y con esto calcula la probabilidad de pertenencia de un punto $x$ a cada clase, y se eliga la clase $k$ con la probabilidad más alta. Se usa la fórmula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Es conveniente utilizarla para casos donde tus datos sigan una distribución normal, ya que usa este supuesto y si en realidad se cumple, los resultados de clasificación serían mejores.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección 4: Cross validation  (10 puntos)  \n",
    "\n",
    "12. **(10 pts) ¿Qué es grid search? ¿qué es random search? Explica las diferencias y cuando usarías cada uno** \n",
    "\n",
    "El grid search es un proceso donde se prueban todas las combinaciones posibles de hiperparámetros de un modelo para así encontrar la mejor combinación. Por otro lado el random search usa valores aleatorios dentro de un rango para probar los hiperparámetros, solo prueba algunas combinaciones posibles.\n",
    "\n",
    "La principal diferencia es que el grid search prueba todas las combinaciones dentro de un rango definido, mientras que random search prueba de forma aleatoria algunas de las combinaciones. El grid search encuentra la mejor combinación posible dentro del rango definido, mientras que el random search no es necesariamente la mejor combinación posible.\n",
    "\n",
    "Es mejor utilizar el grid seacrh cuando se tienen pocos datos e hiperparámetros a probar, se cuenta con una buena cantidad de tiempo y se tiene buen poder computacional, ya que puede llegar a ser pesado de correr. El random search es mejor en casos que se necesite encontrar un modelo de forma rápida y no se tenga tanta capacidad computacional pues es más rápido que grid search y menos exigente para la computadora.\n",
    "\n",
    "---\n",
    "\n",
    "## **Sección 5: Redes Neuronales y Perceptrón Multicapa** (20 puntos)  \n",
    "\n",
    "13. **(5 pts) Explica que es una red neuronal, que hace, como funciona, etc.**\n",
    "\n",
    "Es un algoritmo que permite resolver problemas de regresión y clasificación mediante un sistema de capas. Existe la capa incial con los datos de entrada, estos se pasan a la primer capa oculta como una combinación lineal entre los datos y pesos, esta combinación lineal después se introduce a una función de activación que transfroma los datos de forma no lineal. Estos datos transformados pasan a la siguiente capa como una combinación lineal entre estos y nuevos pesos, el resultado se transforma en una función de activación, y se repite hasta la capa de salida que es lo que se quiere predecir. Este proceso es el forward propagation, depués se realiza el backpropagation que es donde la red neuronal aprende; se calcula el error y este se distribuye a todas las neuronas de las capas anteriores para saber que tanto influye cada uno de los pesos, después los pesos se ajustan utilizando el descenso en gradiente, esto se hace de forma iterativa para mejorar el modelo y reducir el error.\n",
    " \n",
    "14. **(5 pts) ¿Cuál es el propósito de la **backpropagation** en el entrenamiento de redes neuronales?**\n",
    "\n",
    "El backpropagation es donde se entrena y aprende la red neuronal, pues es un método que usa el descenso en gradiente, donde calcula las derivadas parciales de la función de costo respecto a cada peso y sesgo. Estas derivadas son usadas para actualizar los pesos y sesgos de forma que se reduzca el error del modelo.\n",
    "\n",
    "15. **(5 pts) A grandes rasgos, explica como obtenemos los coeficientes de una red neuronal**\n",
    "\n",
    "Se obtienen a través del backpropagation que permite actualizar los pesos y sesgos de la red neuronal.\n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "Estás fórmulas obtienen las derivadas parciales de la función de costo respecto a cada peso y sesgo, depués a cada pesos y sesgo se le resta su derivada parcial multiplicada por un factor de aprendizaje $\\alpha$, esto permite que el modelo vaya en dirección contraria al gradiente en cada iteración, lo cual minimiza la función de pérdida y encuentra los coeficientes óptimos del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## **Sección 6: Softmax** (10 puntos)  \n",
    "16. **(5 pts) Explica que es softmax, para que sirve y como se calcula**\n",
    "\n",
    "Se utiliza similar a la regresión logística, pero para problemas de clasificación de más de dos clases. La función Softmax convierte las salidas de la combinación lineal de los coeficientes con las características en probabilidades.\n",
    "\n",
    "Con este proceso se calcula la probabilidad de que un dato pertenezca a cada una de las clases y se le asigna la que tiene el valor con la predicción más alto.\n",
    "\n",
    "Lo que se hace es que cada una de las clases tiene distintos coeficientes para cada característica, se introduce un nuevo dato (vector $X$) y se obtiene $z$ de la siguiente forma: $z = \\theta^T X$ para cada una de las clases, después cada valor de $z$ obtenido se introduce la sigueinte fórmula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n",
    "El valor de $z$ que arroje la probabilidad más alta es la clase a donde se asigna el nuevo dato.\n",
    "\n",
    "---\n",
    "\n",
    "## **Puntaje Total: 100 puntos**  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
